# Datus-agent

---
# Deployment

## Pulling submodule code locally
```bash
git submodule update --init
```

## Install the Necessary Dependencies

### Using `uv`

```bash
# Create a virtual environment
uv venv -p 3.12

# Synchronize all dependencies
uv sync
# with dev dependencies
uv sync --dev

# Use current environment
source .venv/bin/activate
```

### Using `conda`

```bash
conda create -n datus-agent python=3.12
conda activate datus-agent
pip install -r requirements.txt
```

### Using `venv`

```bash
virtualenv datus-agent --python=python3.12
source datus-agent/bin/activate
pip install -r requirements.txt
```

---

## Configuration

### Agent.yml

```bash
cp conf/agent.yml.qs conf/agent.yml
```

Then modify `conf/agent.yml` as needed:

```yaml
agent:
  target: deepseek-v3
  models:
    deepseek-v3:
      type: deepseek
      base_url: https://api.deepseek.com
      api_key: ${DEEPSEEK_API_KEY}
      model: deepseek-chat

    deepseek-r1:
      type: deepseek
      base_url: https://api.deepseek.com
      api_key: ${DEEPSEEK_API_KEY}
      model: deepseek-reasoner

  storage_path: data

  benchmark:
    bird_dev:
      benchmark_path: benchmark/bird/dev_20240627
    spider2:
      benchmark_path: benchmark/spider2/spider2-snow

  namespace: # namespace is a set of database connections
    local_duckdb:
      type: duckdb
      uri: ./tests/duckdb-demo.duckdb
    spider-snow:
      type: snowflake
      warehouse: ${SNOWFLAKE_WAREHOUSE}
      account: ${SNOWFLAKE_ACCOUNT}
      username: ${SNWOFLAKE_USER}
      password: ${SNOWFLAKE_PASSWORD}
    bird_sqlite:
      type: sqlite
      path_pattern: benchmark/bird/dev_20240627/dev_databases/**/*.sqlite

  storage:
    base_path: data
    # Local model recommendations:
    # 1. For extreme performance: all-MiniLM-L6-v2 (~100M) or intfloat/multilingual-e5-small (~460M)
    # 2. For balanced performance and quality: intfloat/multilingual-e5-large-instruct (~1.2G)
    # 3. For optimal retrieval quality: BAAI/bge-large-en-v1.5 or BAAI/bge-large-zh-v1.5 (~3.6G)
    # You can also select any model that suits your requirements.
    # Default: all-MiniLM-L6-v2 if no model is configured.
    # Claude model suggestions: Now we just support openai.
    database:
      registry_name: sentence-transformers # default is sentence-transformers, now just support sentence-transformers and openai.
      model_name: text-embedding-v3
      dim_size: 1024
      # batch_size: 10 # This configuration is required when the registration mode is openai
    document:
      model_name: intfloat/multilingual-e5-large-instruct
      dim_size: 1024
    metric:
      model_name:  all-MiniLM-L6-v2
      dim_size: 384
```

You can configure multiple models and databases. The `target` is the default model to use.

---

### Langsmith (Optional)

Set the following environment variables for Langsmith integration:

```env
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=xxx
LANGSMITH_PROJECT=Datus-agent
```

---

# Have a Try

## Test Connection

```bash
python -m datus.main probe-llm
```

Example Output:
```
LLM model test successful
Final Result: {"status": "success", "message": "LLM model test successful", "response": "Yes, I can 'hear' you! ðŸ˜Š How can I assist you today?"}
```

```bash
python -m datus.main check-db --namespace local_duckdb
```

---

## Run SQL

```bash
python -m datus.cli.main --namespace local_duckdb --config conf/agent.yml

Datus> select * from tree;
â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ Continent â”ƒ TradingBloc â”ƒ Country    â”ƒ GDP    â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ NA        â”‚ US          â”‚ US         â”‚ 19.485 â”‚
â”‚ Asia      â”‚ China       â”‚ China      â”‚ 12.238 â”‚
â”‚ Asia      â”‚ Japan       â”‚ Japan      â”‚ 4.872  â”‚
â”‚ Europe    â”‚ EU          â”‚ Germany    â”‚ 3.693  â”‚
â”‚ Asia      â”‚ India       â”‚ India      â”‚ 2.651  â”‚
â”‚ Europe    â”‚ UK          â”‚ UK         â”‚ 2.638  â”‚
â”‚ Europe    â”‚ EU          â”‚ France     â”‚ 2.583  â”‚
â”‚ SA        â”‚ Brazil      â”‚ Brazil     â”‚ 2.054  â”‚
â”‚ Europe    â”‚ EU          â”‚ Italy      â”‚ 1.944  â”‚
â”‚ NA        â”‚ US          â”‚ Canada     â”‚ 1.647  â”‚
â”‚ Europe    â”‚ Russia      â”‚ Russia     â”‚ 1.578  â”‚
â”‚ Asia      â”‚ SouthKorea  â”‚ SouthKorea â”‚ 1.531  â”‚
â”‚ Australia â”‚ Australia   â”‚ Australia  â”‚ 1.323  â”‚
â”‚ Europe    â”‚ EU          â”‚ Spain      â”‚ 1.314  â”‚
â”‚ NA        â”‚ US          â”‚ Mexico     â”‚ 1.151  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Returned 15 rows in 0.03 seconds

Datus> .help
```

---

# Spider2 Benchmark

## Initialization

Update `agent.yml` if needed:

```yaml
benchmark:
  spider2:
    benchmark_path: benchmark/spider2/spider2-snow

namespace:
  spidersnow:
    type: snowflake
    username: ${SNOWFLAKE_USER}
    account: ${SNOWFLAKE_ACCOUNT}
    warehouse: ${SNOWFLAKE_WAREHOUSE}
    password: ${SNOWFLAKE_PASSWORD}
```

### Bootstrap Knowledge Base

```bash
python -m datus.main bootstrap-kb --namespace spidersnow --benchmark spider2 --kb_update_strategy overwrite
```

> âš ï¸ May take hours (approx. 14,000 tables).

### Run Test by IDs

```bash
python -m datus.main benchmark --namespace spidersnow --benchmark spider2 --benchmark_task_ids sf_bq104
```

```bash
python -m datus.cli.main --namespace spidersnow  --config conf/agent.yml

Datus> !darun_screen
Creating a new SQL task
Enter task ID (49856268):
Enter task description (): Based on the most recent refresh date, identify the top-ranked rising search term for the week that is exactly one year prior to the latest available week in the dataset.
Enter database name: GOOGLE_TRENDS
Enter output directory (output):
Enter external knowledge (optional) ():
SQL Task created: 49856268
Database: snowflake - GOOGLE_TRENDS

```
---

# Bird Benchmark

## Initialization

Update Configuration:

```yaml
benchmark:
  bird_dev:
    benchmark_path: benchmark/bird/dev_20240627

namespace:
  bird_sqlite:
    type: sqlite
    path_pattern: benchmark/bird/dev_20240627/dev_databases/**/*.sqlite
```

### Download and Extract Bird Dev

```bash
wget https://bird-bench.oss-cn-beijing.aliyuncs.com/dev.zip
unzip dev.zip
mkdir -p benchmark/bird
mv dev_20240627 benchmark/bird
cd benchmark/bird/dev_20240627
unzip dev_databases
cd ../../..
```

### Bootstrap Knowledge Base

```bash
python -m datus.main bootstrap-kb --namespace bird_sqlite --benchmark bird_dev --kb_update_strategy overwrite
```

### Run Tests

```bash
python -m datus.main benchmark --namespace bird_sqlite --benchmark bird_dev --plan fixed --schema_linking_rate medium --benchmark_task_ids 14 15
```

```bash
python -m datus.main benchmark --namespace bird_sqlite --benchmark bird_dev --schema_linking_rate fast --benchmark_task_ids 32
```

```bash
python -m datus.main benchmarking --benchmark bird_dev --plan fixed --schema_linking_model medium
```

### Using cli to develop

```bash
python -m datus.cli.main --namespace bird_sqlite  --config conf/agent.yml
```

# Semantic Layer Benchmark

## Initialization

Install Metricflow:

```bash
# poetry config virtualenvs.in-project true
poetry lock
poetry install
source .venv/bin/activate

# make sure these commands succeeded
mf setup
mf tutorial
mf validate-configs
```

Update Configuration `~/.metricflow/config.yml`:

```yml
model_path: </path/to/semantic-models-dir>
dwh_schema: mf_demo
dwh_dialect: duckdb
dwh_database: <home dir>/.metricflow/duck.db
```

Update Configuration conf/agent.yml:

```yaml
namespace:
  duckdb:
    type: duckdb
    name: duck
    uri: ~/.metricflow/duck.db

benchmark:
  semantic_layer:
    benchmark_path: benchmark/semantic_layer

metrics:
  tutorial:
    domain: sale
    layer1: layer1
    layer2: layer2
    ext_knowledge: ""
```

Export Environment Variables:
```bash
export MF_PATH=</path/to/metricflow>/.venv/bin/mf
export MF_VERBOSE=true
export MF_MODEL_PATH=</path/to/semantic-models-dir>
```

### Bootstrap Metrics Generation

```bash
python -m datus.main bootstrap-kb --namespace duckdb --components metrics --metric_meta tutorial --kb_update_strategy overwrite
```

### Run Tests

```bash
python -m datus.main benchmark --namespace duckdb --benchmark semantic_layer --plan metric_to_sql --metric_meta tutorial
```